<!DOCTYPE html><html><head>
      <title>video-streaming</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script
  src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/js/all.min.js"
  crossorigin="anonymous"
></script>
<style>
body {
  font-family: 'Open Sans', sans-serif;
  width: 100%;
  height: 100%;
  top: 0;
  margin: 0;
  padding: 2em calc(max(50% - 457px + 2em, 1em));
  position: relative;
  font-size: 16px;
  line-height: 1.6;
  background-color: #fff;
  overflow: initial;
  box-sizing: border-box;
  word-wrap: break-word;
  color: black;
  background-color: white;
  -webkit-print-color-adjust: exact;
  print-color-adjust: exact;
}
body > :first-child {
  margin-top: 0;
}
body h1,
body h2,
body h3,
body h4,
body h5,
body h6 {
  color: black;
  padding-bottom: 8px;
  border-bottom: 1px solid black;
  font-weight: 600;
  margin-top: 1em;
  margin-bottom: 16px;
  line-height: 1.2;
}
body h1 {
  font-size: 2.25em;
  padding-bottom: 0.3em;
}
body h2 {
  font-size: 1.75em;
  padding-bottom: 0.3em;
}
body h3 {
  font-size: 1.5em;
}
body h4 {
  font-size: 1.25em;
}
body h5 {
  font-size: 1.1em;
}
body h6 {
  font-size: 1em;
}
body p + ul {
  margin-top: -15px;
}
body a:not([href]) {
  color: inherit;
  text-decoration: none;
}
body a {
  color: #08c;
  text-decoration: none;
}
body a:hover {
  color: #00a3f5;
  text-decoration: none;
}
body > p {
  margin-top: 0;
  margin-bottom: 16px;
  word-wrap: break-word;
}
body > ol,
body > ul {
  margin-bottom: 16px;
}
body ol,
body ul {
  padding-left: 2em;
}
body ol ol,
body ol ul,
body ul ol,
body ul ul {
  margin-top: 0;
  margin-bottom: 0;
}
body li {
  margin-bottom: 0;
}
body li > p {
  margin-top: 0;
  margin-bottom: 0;
}
body code {
  font-family: ui-monospace, SFMono-Regular, SF Mono, Menlo, Consolas, Liberation Mono, monospace;
  font-size: 1em;
  padding: 0.15em 0.25em;
  margin: 0;
  white-space: break-spaces;
  background-color: #afb8c133;
  border-radius: 6px;
  color: #000000;
}
body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  color: #1f2328;
  background-color: #e3e6e9;
  border-radius: 6px;
}
body pre > code {
  padding: 0;
  margin: 0;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}
body hr {
  height: 1px;
  margin: 8px 0;
  background-color: #000000;
  border: 0 none;
}
body table {
  margin: 10px 0 15px 0;
  border-collapse: collapse;
  border-spacing: 0;
  display: block;
  width: 100%;
  overflow: auto;
  word-break: normal;
  word-break: keep-all;
}
body table th {
  font-weight: 700;
  color: #000;
}
body table td,
body table th {
  border: 1px solid #d6d6d6;
  padding: 6px 13px;
}
body dl {
  padding: 0;
}
body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: 700;
}
body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}
body ul {
  list-style: disc;
}
body ul ul {
  list-style: circle;
}
body ul ul ul {
  list-style: square;
}
body own-preview ol {
  list-style: decimal;
}
body own-preview ol ol,
body ul ol {
  list-style-type: lower-roman;
}
body own-preview ol ol ol,
body own-preview ol ul ol,
body ul ol ol,
body ul ul ol {
  list-style-type: lower-alpha;
}
body img {
  width: 100%;
  display: block;
  margin-left: auto;
  margin-right: auto;
  margin-bottom: 25px;
}
body .image-caption {
  font-size: 0.8em;
  color: #494949;
  text-align: center;
  margin: -20px auto 10px;
  width: 100%;
}
body .definition {
  border-color: #06c406;
}
body .definition .title {
  background-color: #d9ffd9;
}
body .info {
  border-color: #448aff;
}
body .info .title {
  background-color: #ecf3ff;
}
body .proposition {
  border-color: #448aff;
}
body .proposition .title {
  background-color: #ecf3ff;
}
body .theorem {
  border-color: #448aff;
}
body .theorem .title {
  background-color: #ecf3ff;
}
.admonition {
  border: 1px solid;
  border-radius: 8px;
  margin-bottom: 10px;
}
.admonition .title {
  font-size: 1em;
  font-weight: 600;
  padding: 4px 10px;
  border-radius: 8px 8px 0px 0px;
}
.admonition .title svg {
  margin-right: 4px;
}
.admonition .title p {
  margin: 0px;
}
.admonition .body {
  padding: 8px 10px 0px;
}
.admonition .body > :first-child {
  margin-top: 0;
}
.admonition .body > :last-child {
  margin-bottom: 4px;
}
</style>
</head>
<body><h2>Video Streaming</h2>
<ul>
<li>Over 3/4 of bits send over the Internet are video</li>
<li>In early days, sending uncompressed video would be way too much (740 megabits per second when we could only do like 20)</li>
<li><strong>Intra-frame compression</strong>:<ul>
<li>Compressing an image only relative to itself</li>
<li>Divide component into blocks (i.e. 8x8)</li>
<li>For each channel of each component, predict from surrounding blocks what this component is</li>
<li>Take the residue (what&#39;s left / not predicted) and transform it (i.e. some change of basis)</li>
<li>Then quantize this to throw away some higher level information but keep the general picture</li>
<li>Then use some compression algorithm to transmit this (i.e. Huffman codes)</li>
</ul>
</li>
<li><strong>Inter-frame compression</strong><ul>
<li>Divide frame into macroblocks</li>
<li>For each macroblock, encode with either the intra-frame compression discussed before</li>
<li>Or predict by shifting / warping part of a reference frame and then compressing the residue</li>
<li>The resulting frame can be either displayed and/or stored as a reference frame for future compression</li>
<li>The reference frame could be from the future or past</li>
</ul>
</li>
<li>A macroblock can be labeled as:<ul>
<li>I: from intra-frame</li>
<li>P: predicted from past</li>
<li>B: bilteral prediction from the future</li>
</ul>
</li>
</ul>
<h3>Bitrate</h3>
<ul>
<li>What is bitrate?</li>
<li>Problem: it is no longer predictable how many bits each frame will consume<ul>
<li>In the best case, we have a single frame that takes some kb and then everything else is 0</li>
<li>Or in the worst case, everything requires the same amount of kb to display the entire image</li>
</ul>
</li>
<li>Target decoder model:<ul>
<li>We have a buffer that is filling with information at some constant network speed<ul>
<li>Buffer occupancy can be measured in either bytes or seconds</li>
</ul>
</li>
<li>In &quot;random&quot; spurts, it is decreasing as we take frames out of the buffer</li>
</ul>
</li>
<li>What it means for a video to have a certain bitrate is:<ul>
<li>If bytes stream in at that rate and the buffer has a certain max occupancy and the video starts playing when the buffer reaches a certain occupancy, then the video can play without interruption and without the buffer ever filling up</li>
<li>This means that saying a video has a certain bitrate means you have to provide three numbers:<ul>
<li>The bitrate</li>
<li>Buffer maximum size</li>
<li>Initial playback delay</li>
</ul>
</li>
</ul>
</li>
<li>How can we reduce required bitrate?<ul>
<li>Can make it look worse (reduce quality) by reducing picture quality or framerate</li>
</ul>
</li>
</ul>
<h3>Playback</h3>
<ul>
<li>When can you start playing frames?</li>
<li>If every frame was the same size, you could just wait until you got a single frame<ul>
<li>Or you could just wait until your buffer filled</li>
<li>You could also do some backwards computation to figure it out</li>
</ul>
</li>
<li>Services like YouTube offer multiple possible bitrates</li>
<li>How does this make the choice automatically?<ul>
<li>Segmented streaming with bitrate adaptation (around the 2008 Olympics)</li>
<li>We divide the video into independent segments<ul>
<li>Between segments, no inter-frame prediction</li>
</ul>
</li>
<li>This means that at every segment, there is a decision opportunity for what bitrate to get this segment at</li>
<li>At each segment, we use an ABR policy to choose the appropriate bitrate<ul>
<li>The first policies estimated throughput then picked the highest feasible</li>
<li>This is done client-side</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>However, choosing bitrate based on throughput has problems:</p>
<ul>
<li>Estimating current throughput is challenging<ul>
<li>When using TCP, if there is a missing packet, the application will only see up to that hole, even if in reality you are getting many many packetes beyond that hole<ul>
<li>Therefrom the application layer, they can&#39;t really see what the throughput is</li>
</ul>
</li>
</ul>
</li>
<li>Future throughput is even moreso<ul>
<li>Video streaming clients experience highly variable e2e throughput</li>
</ul>
</li>
</ul>
<h3>Buffer Occupancy Based Playback</h3>
<p>In 2013, a new KISS idea came out: base it all on buffer occupancy</p>
<ul>
<li>If the buffer occupancy is low, use a low quality</li>
<li>If it is high, use a higher quality</li>
</ul>
<hr>
<p><img style="" src="img/bba-example.png"/></p>
<ul>
<li>Main idea: if our throughput is enough to sustain a certain bitrate, then we will be able to download faster than we consume and be able to stay in these certain ranges</li>
<li>Why did this specific example work?<ul>
<li>The minimum speed we really care about is the 1Mb/s because that&#39;s the lowest bitrate we offer</li>
<li>Using that as the minimum, this basically just says that if we go over 16s and switch to 16 Mb/s, then even if we drop down to the lowest bitrate, we will still ahve enough buffer to download the next chunk before the buffer runs out<ul>
<li>And then we can switch over to the lower bitrate because we ran out of buffer</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>&quot;Optimal&quot; Streaming Algorithms</h3>
<ul>
<li>After this came out, researchers started adding more parameters alongside the buffer occupancy<ul>
<li>They started using models to predict the future download time and got an objective function that they could optimize for minimizing quality variation / stalls</li>
<li>They also tried online reinforcement learning</li>
</ul>
</li>
<li>They outperformed the simple buffer occupancy algorithm but when they attempted to replicate it in real world settings:<ul>
<li>The same held here: the &quot;dumb&quot; BBA scheme just outperformed<br><img style="" src="img/video-streaming-bba-graph.png"/></li>
<li>To get this data, Stanford created a website that rebroadcasts free TV and people can watch online<ul>
<li>They vary the algorithms used for people and measure a lot of data</li>
</ul>
</li>
</ul>
</li>
<li>There was one thing called Fugu that did end up becoming better<ul>
<li>Uses a lot of ML sophistication and has to use training data (i.e. from the previous day on the same website) to make predictions on transmission time</li>
</ul>
</li>
</ul>
<h2>Real Time Video</h2>
<ul>
<li>Typically, the video codec and actual transport (TCP) logic are separate<ul>
<li>Can think of it as two different control loops that are running in parallel</li>
<li>The codec sends compressed frames to the transport, and the transport sends a new target bit rate back to the codec<br><img style="" src="img/codec-transport-interface.png"/></li>
</ul>
</li>
<li>As a result, it is hard for the video codec to integrate well with the transport logic</li>
<li>Improving one at a time can help, but can still lead to issues since the codec can&#39;t know the TCP<ul>
<li>I.e. if you have a large frame to send, and it causes the TCP window to expand, this might cause the buffer to overflow, and then the TCP drops again and you can&#39;t send the smaller frames now</li>
</ul>
</li>
<li>Salsify:<ul>
<li>Idea is you can encode the idea of skipping frames so that right before sending a frame, you ask the TCP transport layer if there is enough space to send this, and if there isn&#39;t, then you can choose to skip a frame and not send<ul>
<li>Avoids overwhelming the TCP queues / congestion windows</li>
</ul>
</li>
<li>The other key idea behind this is that when encoding, you encode two versions, one a higher quality version and one a lower quality version and you ask the transport layer which of these can fit (if any) and use that to inform your decision</li>
</ul>
</li>
</ul>
</body></html>