<!DOCTYPE html><html><head>
      <title>temporary</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script
  src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/js/all.min.js"
  crossorigin="anonymous"
></script>
<style>
body {
  font-family: 'Open Sans', sans-serif;
  width: 100%;
  height: 100%;
  top: 0;
  margin: 0;
  padding: 2em calc(max(50% - 457px + 2em, 1em));
  position: relative;
  font-size: 16px;
  line-height: 1.6;
  background-color: #fff;
  overflow: initial;
  box-sizing: border-box;
  word-wrap: break-word;
  color: black;
  background-color: white;
  -webkit-print-color-adjust: exact;
  print-color-adjust: exact;
}
body > :first-child {
  margin-top: 0;
}
body h1,
body h2,
body h3,
body h4,
body h5,
body h6 {
  color: black;
  padding-bottom: 8px;
  border-bottom: 1px solid black;
  font-weight: 600;
  margin-top: 1em;
  margin-bottom: 16px;
  line-height: 1.2;
}
body h1 {
  font-size: 2.25em;
  padding-bottom: 0.3em;
}
body h2 {
  font-size: 1.75em;
  padding-bottom: 0.3em;
}
body h3 {
  font-size: 1.5em;
}
body h4 {
  font-size: 1.25em;
}
body h5 {
  font-size: 1.1em;
}
body h6 {
  font-size: 1em;
}
body p + ul {
  margin-top: -15px;
}
body a:not([href]) {
  color: inherit;
  text-decoration: none;
}
body a {
  color: #08c;
  text-decoration: none;
}
body a:hover {
  color: #00a3f5;
  text-decoration: none;
}
body > p {
  margin-top: 0;
  margin-bottom: 16px;
  word-wrap: break-word;
}
body > ol,
body > ul {
  margin-bottom: 16px;
}
body ol,
body ul {
  padding-left: 2em;
}
body ol ol,
body ol ul,
body ul ol,
body ul ul {
  margin-top: 0;
  margin-bottom: 0;
}
body li {
  margin-bottom: 0;
}
body li > p {
  margin-top: 0;
  margin-bottom: 0;
}
body code {
  font-family: ui-monospace, SFMono-Regular, SF Mono, Menlo, Consolas, Liberation Mono, monospace;
  font-size: 1em;
  padding: 0.15em 0.25em;
  margin: 0;
  white-space: break-spaces;
  background-color: #afb8c133;
  border-radius: 6px;
  color: #000000;
}
body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  color: #1f2328;
  background-color: #e3e6e9;
  border-radius: 6px;
}
body pre > code {
  padding: 0;
  margin: 0;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}
body hr {
  height: 1px;
  margin: 8px 0;
  background-color: #000000;
  border: 0 none;
}
body table {
  margin: 10px 0 15px 0;
  border-collapse: collapse;
  border-spacing: 0;
  display: block;
  width: 100%;
  overflow: auto;
  word-break: normal;
  word-break: keep-all;
}
body table th {
  font-weight: 700;
  color: #000;
}
body table td,
body table th {
  border: 1px solid #d6d6d6;
  padding: 6px 13px;
}
body dl {
  padding: 0;
}
body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: 700;
}
body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}
body ul {
  list-style: disc;
}
body ul ul {
  list-style: circle;
}
body ul ul ul {
  list-style: square;
}
body own-preview ol {
  list-style: decimal;
}
body own-preview ol ol,
body ul ol {
  list-style-type: lower-roman;
}
body own-preview ol ol ol,
body own-preview ol ul ol,
body ul ol ol,
body ul ul ol {
  list-style-type: lower-alpha;
}
body img {
  width: 100%;
  display: block;
  margin-left: auto;
  margin-right: auto;
  margin-bottom: 25px;
}
body .image-caption {
  font-size: 0.8em;
  color: #494949;
  text-align: center;
  margin: -20px auto 10px;
  width: 100%;
}
body .definition {
  border-color: #06c406;
}
body .definition .title {
  background-color: #d9ffd9;
}
body .info {
  border-color: #448aff;
}
body .info .title {
  background-color: #ecf3ff;
}
body .proposition {
  border-color: #448aff;
}
body .proposition .title {
  background-color: #ecf3ff;
}
.admonition {
  border: 1px solid;
  border-radius: 8px;
  margin-bottom: 10px;
}
.admonition .title {
  font-size: 1.125em;
  font-weight: 600;
  padding: 4px 10px;
  border-radius: 8px 8px 0px 0px;
}
.admonition .title svg {
  margin-right: 4px;
}
.admonition .title p {
  margin: 0px;
}
.admonition .body {
  padding: 8px 10px 0px;
}
.admonition .body > :first-child {
  margin-top: 0;
}
.admonition .body > :last-child {
  margin-bottom: 4px;
}
</style>
</head>
<body><h1>Google File System</h1>
<h2>Main Structure</h2>
<ul>
<li>Files are split into chunks of 64 MB that are distributed among chunkservers<ul>
<li>Each chunk is replicated three times</li>
</ul>
</li>
<li>A single coordinator keeps track of the filesystem and redirects clients to tell them where the chunks they want are</li>
<li>Reads are simple: coordinator tells client where the chunk is and then the chunk server goes and grabs it<ul>
<li>This can read stale data if a chunkserver&#39;s location is cached by a client</li>
<li>Will be fixed when the chunkserver is garbage collected or the cache expires</li>
<li>This can go to any of the replicas</li>
</ul>
</li>
</ul>
<h2>Writes</h2>
<ul>
<li>When a write is wanted, a lease is granted to one of the replicas that makes it the primary</li>
<li>Clients send data to all replicas and after they all confirm that they have received the data, the client issues a write to the primary<ul>
<li>The primary chooses the order for all client writes and then sends the writes to the secondaries</li>
<li>Concurrent writes at the same time might come in and the replica just chooses some random order for them</li>
</ul>
</li>
<li>If any of the operations fail (i.e. a secondary does not respond / crashes), then the client is informed and tries again<ul>
<li>Our consistency guarantees only hold if the write (after multiple tries) eventually succeeds</li>
</ul>
</li>
</ul>
<h2>Consistency Guarantees</h2>
<p>Two important definitions:</p>
<ul>
<li>Consistent - all clients will seem the same data regardless of which replica</li>
<li>Defined - consistent <strong>and</strong> the mutation is seen in its entirety (not corrupted data)</li>
</ul>
<p><strong>Writes</strong></p>
<ul>
<li>If only one client writes to a chunk at a time, we get consistency</li>
<li>If we have multiple clients writing to a chunk, then we get consistency, but at chunk borders, we might get undefined regions<ul>
<li>Writes are split up at chunk borders, so if the primary chooses a weird order, then we could get half of one write at one side of a chunk border and half of one write on the other side</li>
<li>Then we have some corrupted data where neither write has its full data put to the system</li>
</ul>
</li>
<li>Assuming our write operation succeeds, this will always result in one of these two and not inconsistent data</li>
</ul>
<p><strong>Atomic Appends</strong></p>
<ul>
<li>For these appends, we just care that our data is added to the file <strong>at least once</strong>, we don&#39;t care if some replicas get more copies of the data than others</li>
<li>With atomic appends, we always get defined and consistent regions interspersed with some inconsistent stuff</li>
<li>If one replica fails the atomic append, then we just keep retrying and potentially add duplicates to the replicas that already have the data, but that&#39;s ok</li>
<li>After the atomic append completes, then a whole bunch of space might be unusable but that&#39;s ok and GFS will handle that</li>
<li>This may seem bad, but Google applications are built with this in mind and know that they have to filter duplicate data / do stuff</li>
</ul>
<h2>Handling Server Faults</h2>
<h3>Secondary Goes Down while Writing</h3>
<ul>
<li>In the case that the server is revived quickly, then this can be fine</li>
<li>If not, the primary will throw an error to the client</li>
<li>The client can retry and just keep issuing the write</li>
<li>If the server is permanently down, eventually the coordinator will notice (since lack of heartbeat)<ul>
<li>Then the coordinator will remove the failed chunkserver, rereplicate, and then tells the primary a new list so the write will eventually succeed</li>
</ul>
</li>
</ul>
<h3>Rereplicating Chunkserver</h3>
<ul>
<li>There&#39;s a tradeoff between replicating a chunkserver and not because it&#39;s a lot of work (an hour or two) and so the coordinator may let the system operate without that chunk replica before declaring it dead</li>
<li>But waiting too long might risk allowing all copies of the data to die</li>
</ul>
<h3>Primary Crashes</h3>
<ul>
<li>Wait for the lease for that crashed primary to expire and then issue a new one<ul>
<li>This is the whole point of the leases</li>
</ul>
</li>
</ul>
<h3>Coordinator Crashes</h3>
<ul>
<li>Coordinator saves critical state to disk to try to keep state intact in case of restart</li>
<li>Or you can keep a backup coordinator that takes over when bad</li>
</ul>
<h2>Garbage Collection</h2>
<ul>
<li>GFS does not immediately reclaim available storage, it instead does garbage collection<ul>
<li>It renames a deleted file and after a few days it deletes this file (in the master file tree)</li>
<li>It periodic heartbeats with chunkservers, the master checks if any chunks don&#39;t have any files pointing to them<ul>
<li>The chunkserver then deletes these</li>
</ul>
</li>
</ul>
</li>
<li>If a chunkserver misses mutations, then it is considered stale and will be garbage collected as soon as the master notices its version number is out of date<ul>
<li>This can occur if a write fails</li>
</ul>
</li>
</ul>
<h2>Takeaways</h2>
<ul>
<li>GFS sacrifices consistency for simplicity<ul>
<li>In retrospect a bit too much</li>
</ul>
</li>
<li>Significantly simpler also because of single coordinator but this adds a bottleneck</li>
<li>Optimized for very large files but when there were a lot of files / smaller files then the system became pretty bad when the coordinator ran out of RAM</li>
<li>If clocks don&#39;t match though, this can be a problem with leases<ul>
<li>Loss of performance if coordinator runs slower than primary</li>
<li>Loss of correctness if coordinator runs faster than primary</li>
</ul>
</li>
</ul>
</body></html>